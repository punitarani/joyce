"""Create user entities table

Revision ID: 003
Revises: 002
Create Date: 2025-09-03 17:57:24.977782

"""

from __future__ import annotations

from typing import Sequence

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "003"
down_revision: str | Sequence[str] | None = "002"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "user_entities",
        sa.Column("id", sa.UUID(), nullable=False),
        sa.Column("user_id", sa.UUID(), nullable=False),
        sa.Column("slug", sa.TEXT(), nullable=False),
        sa.Column("collection", sa.TEXT(), nullable=False),
        sa.Column("type", sa.TEXT(), nullable=False),
        sa.Column("data", postgresql.JSONB(astext_type=sa.Text()), nullable=False),
        sa.Column(
            "created_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column(
            "updated_at",
            postgresql.TIMESTAMP(timezone=True),
            server_default=sa.text("now()"),
            nullable=False,
        ),
        sa.Column("archived_at", postgresql.TIMESTAMP(timezone=True), nullable=True),
        sa.ForeignKeyConstraint(["user_id"], ["auth.users.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("user_id", "slug", name="uq_user_entities_user_slug"),
    )
    op.create_index(
        op.f("ix_user_entities_collection"),
        "user_entities",
        ["collection"],
        unique=False,
    )
    op.create_index(
        "ix_user_entities_data_gin",
        "user_entities",
        ["data"],
        unique=False,
        postgresql_using="gin",
        postgresql_ops={"data": "jsonb_path_ops"},
    )
    op.create_index(
        op.f("ix_user_entities_slug"), "user_entities", ["slug"], unique=False
    )
    op.create_index(
        op.f("ix_user_entities_type"), "user_entities", ["type"], unique=False
    )
    op.create_index(
        "ix_user_entities_user_collection_archived",
        "user_entities",
        ["user_id", "collection", "archived_at"],
        unique=False,
    )
    op.create_index(
        op.f("ix_user_entities_user_id"), "user_entities", ["user_id"], unique=False
    )
    op.create_index(
        "ix_user_entities_user_type_archived",
        "user_entities",
        ["user_id", "type", "archived_at"],
        unique=False,
    )
    op.alter_column(
        "memories",
        "data",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        type_=postgresql.JSONB(astext_type=sa.Text()),
        existing_nullable=False,
    )
    op.alter_column(
        "user_profiles",
        "first_name",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "last_name",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "preferred_name",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "email",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "phone",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "gender",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "location",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        type_=postgresql.JSONB(astext_type=sa.Text()),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "attributes",
        existing_type=postgresql.JSON(astext_type=sa.Text()),
        type_=postgresql.JSONB(astext_type=sa.Text()),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "status",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "version",
        existing_type=sa.VARCHAR(),
        type_=sa.TEXT(),
        existing_nullable=True,
    )
    op.drop_column("user_profiles", "context")
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column(
        "user_profiles",
        sa.Column(
            "context",
            postgresql.JSON(astext_type=sa.Text()),
            autoincrement=False,
            nullable=True,
        ),
    )
    op.alter_column(
        "user_profiles",
        "version",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "status",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "attributes",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        type_=postgresql.JSON(astext_type=sa.Text()),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "location",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        type_=postgresql.JSON(astext_type=sa.Text()),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "gender",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "phone",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "email",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "preferred_name",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "last_name",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "user_profiles",
        "first_name",
        existing_type=sa.TEXT(),
        type_=sa.VARCHAR(),
        existing_nullable=True,
    )
    op.alter_column(
        "memories",
        "data",
        existing_type=postgresql.JSONB(astext_type=sa.Text()),
        type_=postgresql.JSON(astext_type=sa.Text()),
        existing_nullable=False,
    )
    op.drop_index("ix_user_entities_user_type_archived", table_name="user_entities")
    op.drop_index(op.f("ix_user_entities_user_id"), table_name="user_entities")
    op.drop_index(
        "ix_user_entities_user_collection_archived", table_name="user_entities"
    )
    op.drop_index(op.f("ix_user_entities_type"), table_name="user_entities")
    op.drop_index(op.f("ix_user_entities_slug"), table_name="user_entities")
    op.drop_index(
        "ix_user_entities_data_gin",
        table_name="user_entities",
        postgresql_using="gin",
        postgresql_ops={"data": "jsonb_path_ops"},
    )
    op.drop_index(op.f("ix_user_entities_collection"), table_name="user_entities")
    op.drop_table("user_entities")
    # ### end Alembic commands ###
